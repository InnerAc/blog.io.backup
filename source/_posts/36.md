title: hadoop2.6.0分布式配置
date: 2015-12-03 20:48:01
categories: 编程与算法
tags: [hadoop,大数据]
---

# hadoop2.6.0集群搭建-ubuntu14.04

<!--more-->
## 1 物理条件准备
### 1.1 集群准备
两台机器，虚拟机实体机都可以。只要两者可以连通。
### 1.2 系统准备
这里及以下代码使用的系统为ubuntu14.04桌面版64位。只要是linux系统，基本上配置都是差不多的。

然后一个命名为`master`另外一个命名为`slave`
然后在`/etc/hosts`中设置两个节点的`ip`和别名。
```
xxx.xxx.xxx.xxx master
xxx.xxx.xxx.xxx slave
```
## 2 基础环境配置
### 2.1 java安装
在ubuntu下其实已经可以采用ppa来安装了。当然，也可以直接解压安装。在这里只说明ppa安装的方法吧。
```shell
sudo add-apt-repository ppa:webupd8team/java
sudo apt-get update
sudo apt-get install Oracle-java7-installer
```
上述步骤分别为添加oracle-java的源、更新缓存和安装jdk7。

如果想要安装jdk8的话，可以将`Oracle-java7-installer`换成`Oracle-java8-installer`

如果同时拥有两个版本，可以通过`sudo update-java-alternatives -s java-7-oracle`进行切换。

### 2.2 openssh安装
ubuntu14.04桌面版中自带`openssh-client`但是没有`openssh-server`。
所以要安装`openssh-server`.
```shell
sudo apt-get install openssh-server
```
### 2.3 建立双向免密码通讯
通过命令`ssh-keygen -t rsa`所有内容为空一直摁回车，然后再`~/.ssh`文件夹中在生成公钥`id_rsa.pub`和`id_rsa.pub `私钥。

然后将自己的公钥分发到其他节点然后执行`cat id_rsa.pub >> ~/.ssh/authorized_keys`

所有节点都这样执行一遍，即可完成免密码通讯。

## 3 hadoop环境搭建
首先在`apache`官网下载`hadoop2.6.0`.地址如下：

http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz

然后将下载好的压缩包解压到某一个文件夹。在一下的例子中我解压到了`/usr/local/bigdata`下，并且将文件夹改名为`hadoop`.
结构树如下:

- /
- \----usr
- \--------local
- \------------bigdata
- \----------------hadoop
- \--------------------bin
- \--------------------sbin
- \--------------------etc
- \--------------------libexec
- \--------------------include
- \--------------------lib
- \--------------------LICENSE.txt
- \--------------------........

所以`hadoop`的根目录为`/usr/local/bigdata/hadoop`

### 3.1 将环境变量加入.bashrc
打开主目录下的`.bashrc`，然后再里面加入：
```shell
#hadoop
export HADOOP_HOME=/usr/local/bigdata/hadoop
export PATH=$HADOOP_HOME/bin:$PATH
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib"
```

### 3.2 修改`hadooop`中的配置文件
需要修改的配置文件有下面几个

- /hadoop/etc/hadoop/hadoop-env.sh
- /hadoop/etc/hadoop/yarn-env.sh
- /hadoop/etc/hadoop/slaves
- /hadoop/etc/hadoop/core-site.xml
- /hadoop/etc/hadoop/hdfs-site.xml
- /hadoop/etc/hadoop/mapred-site.xml
- /hadoop/etc/hadoop/yarn-site.xml

#### 3.2.1 hadoop-env.sh
修改`java`路径
```sh
# The java implementation to use.
export JAVA_HOME=/usr/lib/jvm/java-7-oracle
```

#### 3.2.2 yarn-env.sh
也是修改`java`路径，同时把注释去掉
```sh
# some Java parameters
export JAVA_HOME=/usr/lib/jvm/java-7-oracle/
```

#### 3.2.3 slaves
增加slave节点的别名，这里就是`slave`

#### 3.2.4 core-site.xml
增加如下内容:
```xml
<configuration>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/usr/local/bigdata/hadoop/tmp</value>
        <description>Abase for other temporary directories.</description>
    </property>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://master:9000</value>
    </property>
    <property>
        <name>io.file.buffer.size</name>
        <value>131072</value>
    </property>
    <property>
        <name>hadoop.proxyuser.spark.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.spark.groups</name>
        <value>*</value>
    </property>
</configuration>
```

#### 3.2.5 hdfs-site.xml
增加如下内容：
```xml
<configuration>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>master:9001</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/usr/local/bigdata/hadoop/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/usr/local/bigdata/hadoop/dfs/data</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>
</configuration>
```

#### 3.2.6 mapred-site.xml
开始是没有这个文件的，需要复制`mapred-site.xml.template`一份，然后改名为`mapred-site.xml`
```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>master:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>master:19888</value>
    </property>
</configuration>
```

#### 3.2.7 yarn-site.xml
在文件中增加如下内容
```xml
<configuration>
    <!-- Site specific YARN configuration properties -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.resourcemanager.address</name>
        <value>master:8032</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.address</name>
        <value>master:8030</value>
    </property>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>master:8035</value>
    </property>
    <property>
        <name>yarn.resourcemanager.admin.address</name>
        <value>master:8033</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>master:8088</value>
    </property>
</configuration>
```
至此，配置文件已经修改完毕，然后可以将整个`hadoop`文件夹分发到其他机器。
因为已经建立了`ssh`双向连接，所以可以直接使用`scp`命令。
```shell
scp -r /usr/local/bigdata/hadoop {your_username}@{your_pc_name}:/usr/local/bigdata
```
### 3.3 格式化`hdfs`
在`hadoop`根目录下执行:
```shell
bin/hdfs namenode -format
```

### 3.4 启动`hadoop`
在`hadoop`根目录下执行:
```shell
sbin/start-all.sh
```
便可以在`http://master:50070`查看到集群信息了。

## 4 hello world
在`hadoop`下，`wordcount`就是他的`hello world`
首先在hadoop的根目录下新建一个文件夹，然后在文件夹中随便复制进去一个文本。
```shell
mkdir input
cat "xxxxxx" >> input/file
```
### 4.1 在hdfs上新建文件夹
```
bin/hadoop fs -mkdir /hhu
bin/hadoop fs -mkdir /hhu/input
```
### 4.2 将文本放到hdfs中
```shell
bin/hadoop fs -put input/ /hhu
```
### 4.3 执行`wordcount`
```shell
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar wordcount /hhu/input/ /output/wordcount1
```

如果执行成功基本就完成了，注意如果日志中出现`job_local[\d]*`的字样，说明还是在本机执行，那就要查看自己的配置哪里没配好了。